<HEAD>
<TITLE>Real-Time Range Sensing Video Camera for Human/Robot Interfacing</TITLE>
</HEAD>
<BODY BGCOLOR="#FFFFFF" TEXT="#000000">
<h4 ALIGN=right>
NASA STTR 2003 Solicitation</B></h4>
<CENTER>
<H2>FORM B -  PROPOSAL SUMMARY</H2>
</CENTER>
<HR SIZE=3 WIDTH=100% align=left NOSHADE>
<table border=0 cellpadding=0 cellspacing=5>
<tr><td><B>PROPOSAL NUMBER:</B></td><td>03-<B>T5.02-9872</B>
 (For NASA Use Only - Chron: 030128)  </td></tr>
<tr><td><B>RESEARCH SUBTOPIC TITLE:</B></td><td>Robotics and Virtual Digital Human Technologies</td></tr>
<tr><td><B>PROPOSAL TITLE:</B></td><td>Real-Time Range Sensing Video Camera for Human/Robot Interfacing</td></tr>
</table>
<P>
<TABLE CELLSPACING=5 CELLPADDING=0 BORDER=0>
<TR><TD COLSPAN=2 ALIGN=LEFT>
<u>SMALL&nbsp;BUSINESS&nbsp;CONCERN&nbsp;(SBC):</u></TD>
<TD COLSPAN=2 ALIGN=LEFT>
<u>RESEARCH&nbsp;INSTITUTION&nbsp;(RI):</u></TD>
</TR>
<TR><TD>
NAME:</TD><TH ALIGN=LEFT> Boulder Nonlinear Systems Inc  </TH>
<TD>NAME:</TD><TH ALIGN=LEFT>University of Kentucky  </TH>
</TR>
<TR><TD>
ADDRESS:</TD><TH ALIGN=LEFT>450 Courtney Way, Unit 107  </TH>
<TD>
ADDRESS:</TD><TH ALIGN=LEFT>102 Kinkead Hall </TH>
</TR>
<TR><TD>
CITY:</TD><TH ALIGN=LEFT>Lafayette</TH>
<TD>CITY:</TD><TH ALIGN=LEFT>Lexington </TH>
</TR>
<TR><TD>
STATE/ZIP:</TD><TH ALIGN=LEFT>CO &nbsp;80026-2786 </TH>
<TD>
STATE/ZIP:</TD><TH ALIGN=LEFT>KY &nbsp;40506-0057 </TH>
</TR>
<TR><TD>
PHONE:</TD><TH ALIGN=LEFT> (303)&nbsp;604-0077  </TH>
<TD>
PHONE:</TD><TH ALIGN=LEFT> (859)&nbsp;257-8288 </TH>
</TR>
</TABLE>
<P>
<B>PRINCIPAL INVESTIGATOR/PROJECT MANAGER</B>
<FONT SIZE=-1>(Name,Email)</FONT><BR>
Laurence Hassebrook&nbsp;UofK&nbsp;859-257-8040 <BR>
lgh@engr.uky.edu <BR>
U.S. Citizen or Legal Resident: <b> Yes </B>
<P>
<B>TECHNICAL ABSTRACT (LIMIT 200 WORDS)</B><BR>
In comparison to stereovision, it is well known that structured-light illumination has distinct advantages including the use of only one camera, being significantly less sensitive to background clutter, and not requiring the target object to have nonambiguous features. But because structured-light illumination requires a scanning process, it is inappropriate for humancomputer interfacing where the movements/gestures of a human subject are of interest. We propose the innovative process of composite pattern design as a means of constructing structured-light illumination patterns that measure surface topologies with only a single image and, thereby, are appropriate for recording real-time depth video. By moving the composite pattern into the Near-Infra-Red wavelength light spectrum and coupling with real-time optical processor, we intend to establish feasibility of a real-time, low latency, ambient light resistant, and high accuracy depth video sensor for producing a depth map of a scene applicable to virtual reality interfaces that permit control of robotic systems through human gestures by way of spatial tracking of user appendages in motion absent any wearable transmitters or markers.
<P>
<B>POTENTIAL NASA COMMERCIAL APPLICATIONS (LIMIT 150 WORDS)</B><BR>
The composite pattern method provides a non-touch human computer interface for applications that would otherwise require VR gloves, helmets and other wearable markers. Applications include cockpit interfacing, human computer interfacing with autonomous systems and robots, visualization of large data sets, tele-collaboration, and assistive technology.  Other applications are in the area of 3-Dimesional data acquisition of surfaces. These applications include industrial inspection, surveillance, robotic object avoidance, and multi-dimensional time-motion study. In contrast to stereovision, composite pattern has active illumination, so it is independent of ambient illumination and works well with smooth featureless objects or scenes.<P>
<B>POTENTIAL NON-NASA COMMERCIAL APPLICATIONS (LIMIT 150 WORDS)</B><BR>
The development of continuous, real-time, structured-light imaging for single-sensor, depth measurement is an important contribution to dynamic 3-D imaging and tracking. There is great potential for this technology in many fields from research microscopy on live specimens to non-invasive analysis of large, dynamic systems. The proposed camera could have a major impact on persons with disabilities by permitting nontouch gestures given the inability of some individuals to don and doff wearable sensors. This proposal addresses many issues raised in a wheelchair interface including the operation of structured-light in sunlight.
<P>
<HR NOSHADE size=3>
</body>
</html>