<HTML>
<HEAD>
	<TITLE>Adaptive LIDAR Vision System for Advanced Robotics</TITLE>
</HEAD>
<BODY BGCOLOR="#FFFFFF" TEXT="#000000">
<TABLE width="100%" border="0" align="center">
  <TR>
	<TD>

		<H4 align=right>NASA SBIR 2014 Solicitation</H4>
		<CENTER><H2>FORM B - PROPOSAL SUMMARY</H2></CENTER>
		<HR align="left" width="100%" SIZE="3" noShade>

		<TABLE cellSpacing="5" cellPadding="0" border="0">
			<TBODY>
				<TR>
					<TD><B>PROPOSAL NUMBER:</B></TD>
					<TD>14-1&nbsp;<B>H20.01-9561</B></TD>
				</TR>
				<TR>
					<TD><B>SUBTOPIC TITLE:</B></TD>
					<TD>Human-Robotic Systems - Manipulation Subsystem and Human-System Interaction</TD>
				</TR>
				<TR>
					<TD><B>PROPOSAL TITLE:</B></TD>
					<TD>Adaptive LIDAR Vision System for Advanced Robotics</TD>
				</TR>
			</TBODY>
		</TABLE>
		<P>
					
		<B>SMALL BUSINESS CONCERN</B> <FONT size=-1>(Firm Name, Mail Address, City/State/Zip, Phone)</FONT><BR>
			Honeybee Robotics Spacecraft Mechanisms Corporation <BR>
			460 West 34th Street <BR>
			New York, NY 10001 - 2320 <BR>
			(646) 459-7819
		<P>
		<B>PRINCIPAL INVESTIGATOR/PROJECT MANAGER</B> <FONT size=-1>(Name, E-mail, Mail Address, City/State/Zip, Phone)</FONT><BR>
		Jason Herman<BR>
		herman@honeybeerobotics.com<BR>
		460 West 34th Street<BR>
		New York, NY 10001 - 2320<BR>
		(646) 459-7819<BR>
		
		
		<P>
		<B>CORPORATE/BUSINESS OFFICIAL</B> <FONT size=-1>(Name, E-mail, Mail Address, City/State/Zip, Phone)</FONT><BR>
		Chris Chapman<BR>
		chapman@honeybeerobotics.com<BR>
		460 West 34th Street<BR>
		New York, NY 10001 - 2320<BR>
		(646) 459-7802<BR>
		
		<P>
		<B>Estimated Technology Readiness Level (TRL) at beginning and end of contract: </B>
		 <br>Begin: 1 
		 <br>End: 3
			<p>
		 <B>Technology Available (TAV) Subtopics </B>
		 <br> Human-Robotic Systems - Manipulation Subsystem and Human-System Interaction   is a Technology Available (TAV) subtopic
							that includes NASA Intellectual Property (IP). Do you plan to use
							the NASA IP under the award?<br>  No
		 
		<P>
		<B>TECHNICAL ABSTRACT</B> (Limit 2000 characters, approximately 200 words)
		<BR>
		Advanced robotic systems demand an enhanced vision system and image processing algorithms to reduce the percentage of manual operation required. Unstructured environments, whether man-mad (e.g., International Space Station) or natural (e.g., Mars), present significant challenges to supervised autonomy or fully autonomous systems &#150; advanced perception sensors and associated software are required.  This will be particularly important both for future long duration exploration missions where the transmit (Tx) / receive (Rx) delay will be substantial and a high degree of autonomy will be required to maximize science gain, as well as for telerobotic systems where a human operator is IVA and advanced operations in a short timeline are desired. No solution currently exists for small robotic platforms.  Honeybee Robotics proposes to develop a compact, wide-angle, Light Detection and Ranging (LIDAR) system that is able to detect dynamic changes in the field of view (FOV) and focus the laser scan pattern centered on the area of interest while maintaining a lower-resolution fixed FOV for robotic path planning, navigation, inspection, and identification tasks.
		<P>
		<B>POTENTIAL NASA COMMERCIAL APPLICATIONS</B> (Limit 1500 characters, approximately 150 words)
		<BR>
		A recent collaborative survey entitled, 'A Roadmap for US Robotics &#150; From Internet to Robotics' identified robust 3D perception, planning and navigation, intuitive human-robot interfaces as critical capability gaps that are cross-cutting for the robotics industry which includes space exploration .  The Adaptive LIDAR System is ideally suited to telerobotic navigation, path planning, inspection, and identification.  This is directly applicable to NASA's planetary exploration initiatives (e.g., Moon, Mars, & NEOs).  Current robotic platforms, such as MER and MSL rovers, require significant manpower to analyze and plan mobility operations to ensure obstacle avoidance as well as identify objects of interest for science operations.  Some of these tasks could be automated with an adaptive LIDAR system greatly enhancing tactical planning algorithms and simplifying crew telerobotic interfaces.  In addition, an adaptive LIDAR system can be used for advanced telerobotic research and development at NASA centers.  To realize advanced telerobotic systems for space exploration, a large amount of development and testing is required both of sensing technologies as well as intelligent control algorithms.  The proposed system will provide a platform for which advanced algorithms can be developed and implemented.
		<P>
		<B>POTENTIAL NON-NASA COMMERCIAL APPLICATIONS</B> (Limit 1500 characters, approximately 150 words)
		<BR>
		Over the past decade, Unmanned Ground Vehicles (UGVs) have proven their worth both on the battlefield and in search and rescue operations.  Thousands of man-transportable Packbot and Talon platforms have been deployed overseas. From explosive ordinance disposal (EOD), to urban search and rescue (USAR), to intelligence, surveillance and reconnaissance (ISR), UGV usage for defense and homeland security initiatives is increasing.  <BR><BR>The UGVs of the future must have advanced degree of autonomy, lowering the attention demands on the operator. Three-dimensional sensing technology is at the heart of such functionality, enabling sophisticated telerobotic manipulation, robust autonomous navigation, and detailed survey and inspection.  A compact LIDAR system that is able to detect dynamic changes in the FOV and focus the laser scan pattern centered on the area of interest while maintaining a lower-resolution fixed FOV for path planning and navigation tasks is the next advancement for UGVs.<BR><BR>In industry, the automation of operations in partially unstructured environments, e.g. pallet transport and stowage, earth moving, steel construction, crop harvesting, requires advanced sensors.  Automation in these more challenging environments is beginning to mature in the mining, agricultural, personal assistance, and logistics industries.  The coming decade will see a large increase in demand for the sensors that enable smarter, more flexible operations.
		<P>
		
		<TABLE cellSpacing="1" cellPadding="2" width="100%" border="0">
		  <TBODY>
		  <TR>
		      <TD><DIV align="left"><B>TECHNOLOGY TAXONOMY MAPPING</B> (NASA's technology taxonomy has been developed by the SBIR-STTR program to disseminate awareness of proposed and awarded R/R&D in the agency. It is a listing of over 100 technologies, sorted into broad categories, of interest to NASA.)</DIV>
		      
				
		</TD>
	      </TR>
		  <TR>
		    <TD>
		      <DIV align="left">
			      3D Imaging<BR>
			      Image Analysis<BR>
			      Perception/Vision<BR>
			      Ranging/Tracking<BR>
			      Robotics (see also Control & Monitoring; Sensors)<BR>
		      </DIV>
		    </TD>
		  </TR>
		 </TBODY>
		</TABLE>
		<HR noShade SIZE="3">
		<FONT size=-1>Form Generated on 04-23-14 17:37</FONT>
	</TD>
  </TR>
</TABLE>
</BODY>
</HTML>
