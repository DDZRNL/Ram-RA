<HTML>
	<HEAD>
		<TITLE>Fusion of Inertial Navigation and Imagery Data</TITLE>
	</HEAD>
	<BODY BGCOLOR="#FFFFFF" TEXT="#000000">
		<h4 ALIGN=right>
			NASA SBIR 2004 Solicitation
		</h4>
		<CENTER><H2>FORM B -  PROPOSAL SUMMARY</H2></CENTER>
		<HR SIZE=3 WIDTH="100%" align=left NOSHADE>
		<table border=0 cellpadding=0 cellspacing=5>
			<tr>
				<td><b>PROPOSAL NUMBER:</b></td>
				<td>04 <B>X6.03-7727</td>
			</tr>
			<tr>
				<td><b>SUBTOPIC TITLE:</b></td>
				<td>Atmospheric Maneuver and Precision Landing</td>
			</tr>
			<tr>
				<td><b>PROPOSAL TITLE:</b></td>
				<td>Fusion of Inertial Navigation and Imagery Data</td>
			</tr>
		</table>
		<P>
		<B>SMALL BUSINESS CONCERN</B>
		<FONT SIZE=-1>(Name, E-mail, Mail Address, City/State/Zip, Phone)</FONT><BR>
		Odyssey Space Research<BR>
		2525 Bay Area Blvd., Suite 460<BR>
		Houston, TX 77058-1572<BR>
		(281)488-7953<BR>
		<P>
		<B>PRINCIPAL INVESTIGATOR/PROJECT MANAGER</B>
		<FONT SIZE=-1>(Name, E-mail, Mail Address, City/State/Zip, Phone)</FONT><BR>
		David  Hammen<BR>
		dhammen@odysseysr.com<BR>
		2525 Bay Area Blvd. Suite 460<BR>
		Houston, TX 77058-1572<BR>
		(281)488-7953<BR>
		<P>
		<B>TECHNICAL ABSTRACT (LIMIT 200 WORDS)</B><BR>
		The innovations of the Fusion of Inertial Navigation and Imagery Data are the application of the concept to the dynamic entry-interface through near-landing phases, the autonomy and (near) real-time requirements of the system, and the focus on satisfying the stringent requirements for reliability and verification for spaceflight. This innovation will allow spacecraft to navigate autonomously, precisely and safely from entry-interface to near-landing. <BR><BR>The plan is to develop automated techniques suitable for onboard software that incorporate recognized objects from imagery data into the vehicle's navigated solution. We will use image processing techniques to compare the imagery with expected views, pattern recognition techniques to identify known objects in the comparison, mechanisms for locating known objects using the navigated state, and filtering techniques to update the navigated state with the errors between the observed and expected results. To qualify as flight software, the proposed solution will be reliable and verifiable, and will satisfy limitations of the onboard equipment. No existing techniques solve all of these problems. Current techniques for incorporating imagery data into navigated solutions use sensors that have significantly shorter ranges, rely on registration markers placed on the target, use ground-based computational equipment, or require human intervention to arrive at a solution.
		<P>
		<B>POTENTIAL NASA COMMERCIAL APPLICATIONS (LIMIT 100 WORDS)</B><BR>
		Improved entry navigation will enhance mission success for robotic and human spaceflight missions to the Moon and to Mars. It is imperative that the success rate be improved significantly before NASA embarks on human missions to Mars. The same technology will also benefit Earth imaging missions, which can enhance navigation by incorporating the science data into the navigation. 
		<P>
		<B>POTENTIAL NON-NASA COMMERCIAL APPLICATIONS (LIMIT 100 WORDS)</B><BR>
		Commercial spaceflight is coming. Using imagery to improve vehicle navigation provides a low-cost, low infrastructure solution that fits the needs for commercial missions to the Moon and beyond. 
		<P>
		<HR NOSHADE size=3>
	</body>
</html>
