<HTML>
<HEAD>
	<TITLE>Adaptive bio-inspired navigation for planetary exploration</TITLE>
</HEAD>
<BODY BGCOLOR="#FFFFFF" TEXT="#000000">
<TABLE width="100%" border="0" align="center">
  <TR>
	<TD>

		<H4 align=right>NASA STTR 2011 Solicitation</H4>
		<CENTER><H2>FORM B - PROPOSAL SUMMARY</H2></CENTER>
		<HR align="left" width="100%" SIZE="3" noShade>

		<TABLE cellSpacing="5" cellPadding="0" border="0">
			<TBODY>
				<TR>
					<TD><B>PROPOSAL NUMBER:</B></TD>
					<TD>11-1&nbsp;<B>T8.03-9888</B></TD>
				</TR>
				<TR>
					<TD><B>RESEARCH SUBTOPIC TITLE:</B></TD>
					<TD>Autonomous Navigation in GNSS-Denied Environments</TD>
				</TR>
				<TR>
					<TD><B>PROPOSAL TITLE:</B></TD>
					<TD>Adaptive bio-inspired navigation for planetary exploration</TD>
				</TR>
			</TBODY>
		</TABLE>
		<P>
					
			<TABLE CELLSPACING="5" CELLPADDING="0" BORDER="0">
			<TR>
				<TD COLSPAN="2" ALIGN="LEFT">
					<U>SMALL&nbsp;BUSINESS&nbsp;CONCERN&nbsp;(SBC):</U>
				</TD>
				<TD COLSPAN="2" ALIGN="LEFT">
					<U>RESEARCH&nbsp;INSTITUTION&nbsp;(RI):</U>
				</TD>
			</TR>
			<TR>
				<TD>NAME:</TD>
				<TH ALIGN="LEFT">Neurala LLC</TH>
				<TD>NAME:</TD>
				<TH ALIGN="LEFT">Trustees of Boston University</TH>
			</TR>
			<TR>
				<TD>STREET:</TD>
				<TH ALIGN="LEFT">846 East 3rd st</TH>
				<TD>STREET:</TD>
				<TH ALIGN="LEFT">881 Commonwealth Ave</TH>
			</TR>
			<TR>
				<TD>CITY:</TD>
				<TH ALIGN="LEFT">South Boston</TH>
				<TD>CITY:</TD>
				<TH ALIGN="LEFT">Boston</TH>
			</TR>
			<TR>
				<TD>STATE/ZIP:</TD>
				<TH ALIGN="LEFT">MA &nbsp;02127 - 2359</TH>
				<TD>STATE/ZIP:</TD>
				<TH ALIGN="LEFT">MA &nbsp;02215 - 1300</TH>
			</TR>
			<TR>
				<TD>PHONE:</TD>
				<TH ALIGN="LEFT">(510) 205-8091</TH>
				<TD>PHONE:</TD>
				<TH ALIGN="LEFT">(617) 353-4365</TH>
			</TR>
			</TABLE>
		<P>
		<B>PRINCIPAL INVESTIGATOR/PROJECT MANAGER</B> <FONT size=-1>(Name, E-mail, Mail Address, City/State/Zip, Phone)</FONT><BR>
		Anatoli Gorchetchnikov<BR>
		anatoli@cns.bu.edu<BR>
		677 Beacon St<BR>
		Boston, MA 02215 - 3201<BR>
		(857) 928-5490<BR>
		
		<P>
		<B>Estimated Technology Readiness Level (TRL) at beginning and end of contract: </B>
		 <br>Begin: 3 
		 <br>End: 4
		 
		<P>
		<B>TECHNICAL ABSTRACT</B> (Limit 2000 characters, approximately 200 words)
		<BR>
		Surface exploration of planetary environments with current robotic technologies relies heavily on human control and power-hungry active sensors to perform even the most elementary low-level functions. Ideally, a robot should be capable of autonomously exploring and interacting within an unknown environment without relying on human input or suboptimal sensors. Behaviors such as exploration of unknown environments, memorizing locations of obstacles or objects, building and updating a representation of the environment, and returning to a safe location, are all tasks that constitute typical activities efficiently performed by animals on a daily basis. Phase I of this proposal will focus on design of an adaptive robotic multi-component neural system that captures the behavior of several brain areas responsible for perceptual, cognitive, emotional, and motor behaviors. This system makes use of passive, potentially unreliable sensors (analogous to animal visual and vestibular systems) to learn while navigating unknown environments as well as build usable and correctable representations of these environments without requiring a Global Navigation Satellite System (GNSS). In Phase I, Neurala and the Boston University Neuromorphics Lab, will construct a virtual robot, or animat, to be developed and tested in an extraterrestrial virtual environment. The animat will use passive sensors to perform a spatial exploration task. The animat will start exploring from a recharging base, autonomously plan where to go based on past exploration and its current motivation, develop and correct an internal map of the environment with the locations of obstacles, select the shortest path of return to its recharging base before battery depletion, then extract the resulting explored map into a human-readable format. In Phase II Neurala will enhance and translate the model to low-power neuromorphic hardware and collaborate with iRobot to test the model in a robotics platform.
		<P>
		<B>POTENTIAL NASA COMMERCIAL APPLICATIONS</B> (Limit 1500 characters, approximately 150 words)
		<BR>
		Technology developed in this project will have a transformative impact on space exploration, and is directly relevant in supporting the key attributes of autonomy to support NASA missions, stated in the OCT roadmap for Robotics, Tele-Robotics and Autonomous Systems (TA04) as, "the ability for complex decision making, including autonomous mission execution and planning, the ability to self-adapt as the environment in which the system is operating changes, and the ability to understand system state and react accordingly." This work addresses two space technology grand challenges which aim to enable transformational space exploration and scientific discovery: all access mobility and surviving extreme space environments. Development of a biologically-inspired, robust, low-power, multi-component brain system able to perform self-localization and mapping will enable robots to autonomously navigate novel terrains without the need of GNSS. By including the ability to learn about an environment as it explores, robotic agents will be able to autonomously negotiate novel terrains and send relevant, intelligently preprocessed information back to a human controller.  Lastly, incorporating high-level decision making and conflict resolution will allow the robot to decide between exploration of its environment and returning to home base for a battery recharge.
		<P>
		<B>POTENTIAL NON-NASA COMMERCIAL APPLICATIONS</B> (Limit 1500 characters, approximately 150 words)
		<BR>
		One of the fundamental challenges of modern robotics is to build autonomous systems that are increasingly able to explore their environment and act upon choices in an intelligent way. The simultaneous localization and mapping (SLAM) problem exemplifies one such challenge. Currently, industry and academic solutions of the SLAM problem rely on accuracy of expensive sensors that are highly sensitive to noise and the complexity of real-world environments. These solutions are suboptimal since they require expensive, precise, and power-hungry sensors. The technology proposed herein mimics an animal's ability to solve the SLAM problem with noisy sensors and without the need of GNSS. Applications of this new technology include guidance systems for: <BR>- Robots navigating in GNSS-denied environment, such as collapsed building in disaster areas (e.g., earthquakes, nuclear power plants);<BR>- Robots for surveillance and scouting of indoor environments, such as urban war zones;<BR>- Microrobots for medical diagnosis, and <BR>- Robots for deep-ocean exploration.
		<P>
		
		<TABLE cellSpacing="1" cellPadding="2" width="100%" border="0">
		  <TBODY>
		  <TR>
		      <TD><DIV align="left"><B>TECHNOLOGY TAXONOMY MAPPING</B> (NASA's technology taxonomy has been developed by the SBIR-STTR program to disseminate awareness of proposed and awarded R/R&D in the agency. It is a listing of over 100 technologies, sorted into broad categories, of interest to NASA.)</DIV>
		      
				
		</TD>
	      </TR>
		  <TR>
		    <TD>
		      <DIV align="left">
			      Algorithms/Control Software & Systems (see also Autonomous Systems)<BR>
			      Analytical Methods<BR>
			      Autonomous Control (see also Control & Monitoring)<BR>
			      Circuits (including ICs; for specific applications, see e.g., Communications, Networking & Signal Transport; Control & Monitoring, Sensors)<BR>
			      Command & Control<BR>
			      Condition Monitoring (see also Sensors)<BR>
			      Data Modeling (see also Testing & Evaluation)<BR>
			      Data Processing<BR>
			      Development Environments<BR>
			      Intelligence<BR>
			      Models & Simulations (see also Testing & Evaluation)<BR>
			      Navigation & Guidance<BR>
			      Perception/Vision<BR>
			      Process Monitoring & Control<BR>
			      Prototyping<BR>
			      Relative Navigation (Interception, Docking, Formation Flying; see also Control & Monitoring; Planetary Navigation, Tracking, & Telemetry)<BR>
			      Robotics (see also Control & Monitoring; Sensors)<BR>
			      Sequencing & Scheduling<BR>
			      Simulation & Modeling<BR>
			      Software Tools (Analysis, Design)<BR>
		      </DIV>
		    </TD>
		  </TR>
		 </TBODY>
		</TABLE>
		<HR noShade SIZE="3">
		<FONT size=-1>Form Generated on 11-22-11 13:44</FONT>
	</TD>
  </TR>
</TABLE>
</BODY>
</HTML>
