<!DOCTYPE html>
<html class="no-js" lang="en"  dir="ltr">
<head>
	<title>STTR-17-1-T4.01-9958 | Abstract - Evidence Meshes for Three-Dimensional Modeling, Visualization, and Navigation</title>
	  <meta charset="utf-8" />
</head>

<body>
<TABLE role="presentation" style="text-align:center; margin-left:auto; margin-right:auto; width:100%;border:0px solid black">
  <TR>
	<TD>
		
		<h4 align="right">NASA STTR 2017 Solicitation</h4>			
		<h2 align="center">FORM B - PROPOSAL SUMMARY</h2>		
		<hr align="left" width="100%" noShade size="3"/>

		
</table>

		<TABLE  role="presentation" cellSpacing="5" cellPadding="0" border="0">
			<TBODY>
				<TR>
					<TD><B>PROPOSAL NUMBER:</B></TD>
					<TD>171&nbsp;<B>T4.01-9958</B></TD>
				</TR>
				<TR>
					<TD><B>RESEARCH SUBTOPIC TITLE:</B></TD>
					<TD>Information Technologies for Intelligent and Adaptive Space Robotics</TD>
				</TR>
				<TR>
					<TD><B>PROPOSAL TITLE:</B></TD>
					<TD>Evidence Meshes for Three-Dimensional Modeling, Visualization, and Navigation</TD>
				</TR>
			</TBODY>
		</TABLE>
		<P>
					
			<TABLE  role="presentation" CELLSPACING="5" CELLPADDING="0" BORDER="0">
			<TR>
				<TD COLSPAN="2" ALIGN="LEFT">
					<U>SMALL&nbsp;BUSINESS&nbsp;CONCERN&nbsp;(SBC):</U>
				</TD>
				<TD  COLSPAN="2" ALIGN="LEFT">
					<U>RESEARCH&nbsp;INSTITUTION&nbsp;(RI):</U>
				</TD>
			</TR>
			<TR>
				<TD>NAME:</TD>
				<TD ALIGN="LEFT">Mesh Robotics, LLC</TD>
				<TD>NAME:</TD>
				<TD ALIGN="LEFT">Carnegie Mellon University</TD>
			</TR>
			<TR>
				<TD>STREET:</TD>
				<TD ALIGN="LEFT">142 Crescent Drive</TD>
				<TD>STREET:</TD>
				<TD ALIGN="LEFT">5000 Forbes Ave</TD>
			</TR>
			<TR>
				<TD>CITY:</TD>
				<TD ALIGN="LEFT">Pittsburgh</TD>
				<TD scope="row">CITY:</TD>
				<TD ALIGN="LEFT">Pittsburgh</TD>
			</TR>
			<TR>
				<TD>STATE/ZIP:</TD>
				<TD ALIGN="LEFT">PA &nbsp;15228 - 1050</TD>
				<TD>STATE/ZIP:</TD>
				<TD ALIGN="LEFT">PA &nbsp;15213 - 3815</TD>
			</TR>
			<TR>
				<TD>PHONE:</TD>
				<TD ALIGN="LEFT">(412) 606-3842</TD>
				<TD>PHONE:</TD>
				<TD ALIGN="LEFT">(412) 268-2000</TD>
			</TR>
			</TABLE>
		<P>
		<B>PRINCIPAL INVESTIGATOR/PROJECT MANAGER</B> <FONT size=-1>(Name, E-mail, Mail Address, City/State/Zip, Phone)</FONT><BR>
		Dr. David Wettergreen<BR>
		dsw@ri.cmu.edu<BR>
		5000 Forbes Ave<BR>
		Pittsburgh, PA 15213 - 3815<BR>
		(412) 268-5421<BR>
		
		
		<P>
		<B>CORPORATE/BUSINESS OFFICIAL</B> <FONT size=-1>(Name, E-mail, Mail Address, City/State/Zip, Phone)</FONT><BR>
		Mr. Michael Wagner<BR>
		mwagner@meshrobotics.com<BR>
		142 Crescent Drive<BR>
		Pittsburgh, PA 15228 - 1050<BR>
		(412) 606-3842<BR>
		
		<P>
		<B>Estimated Technology Readiness Level (TRL) at beginning and end of contract: </B>
		 <br>Begin: 2 
		 <br>End: 4
			<p>
		 <B>Technology Available (TAV) Subtopics </B>
		 <br> Information Technologies for Intelligent and Adaptive Space Robotics   is a Technology Available (TAV) subtopic
							that includes NASA Intellectual Property (IP). Do you plan to use
							the NASA IP under the award?<br>  No
		 
		<P>
		<B>TECHNICAL ABSTRACT</B> (Limit 2000 characters, approximately 200 words)
		<BR>
		As robots are tasked with ever more complex missions, they demand more sophisticated models of the environments in which they must work. Rough-terrain mobility, site surveying, and dexterous manipulation all demand a fully 3D map of the world that simultaneously exhibits large scale and high resolution, a situation we refer to as scale disparity. Most robots discretize the world into a uniform-grid that is used to accumulate evidence from multiple measurements. Unfortunately the memory footprint of such maps grows dramatically with scale disparity. Octrees can lessen memory requirements, but do not fully counteract the exponential growth of the underlying grid representation. In response, we are developing a map representation called an Evidence Mesh that provides the benefits of probabilistic treatment of evidence but performs better under scale disparity. It is based on a triangulated mesh and is compatible with well-known simplification algorithms to represent the shape of objects at adjustable levels of fidelity. Like an evidence grid but unlike other mesh-based mapping methods available today, an Evidence Mesh accumulates evidence about the location of objects through simplification and across multiple sensor measurements, enabling robust noise filtering and avoiding artifacts and aliasing introduced by artificial grid structures.
		<P>
		<B>POTENTIAL NASA COMMERCIAL APPLICATIONS</B> (Limit 1500 characters, approximately 150 words)
		<BR>
		Our work will produce an efficient map-representation that can be used by NASA's terrestrial experiments today and by missions in the future. We plan to release an open-source implementation for use by NASA. Evidence Meshes support Topic TA04 of NASA's RTA Systems Roadmap as follows: An Evidence Mesh is a natural framework for sensor fusion, which has relevance to NASA-relevant tasks such as grasping and manipulating objects. Manipulation tasks like these often face severe challenges from scale disparity. For example, an ISS map for robotic EVA must be large to support path-planning, yet must have sufficient resolution to model the fine geometry of small tools involved in the task. Planetary-surface rovers will also benefit from enhanced terrain mapping capability. Motion planning over very rough terrain (e.g., cliffs, lava tubes) requires large-scale yet high-fidelity terrain maps. Evidence Meshes are well suited for this becaus they address scale disparity and, because they use triangulated meshes, they support a variety of well-known collision detection algorithms. Their probabilistic framework makes Evidence Meshes a natural representation for planning algorithms that deal with uncertainty, such as probabilistic roadmaps. Evidence Meshes will also benefit existing visualization tools for mission planners and science teams by providing an efficient, compressible data format for transmitting maps via low-bandwidth communications channels.
		<P>
		<B>POTENTIAL NON-NASA COMMERCIAL APPLICATIONS</B> (Limit 1500 characters, approximately 150 words)
		<BR>
		The challenge of scale disparity abounds in industrial and commercial applications, so Evidence Meshes have clear potential outside NASA. For example, driverless cars model the road ahead with grids that can be on the order of 100 meters but must model potentially dangerous objects that are only tens of centimeters in size. Indoor applications that need fully 3D maps, such as robotic manipulation for assembly or for household tasks, suffer even more from the scale-disparity problem. We see the potential for Evidence Meshes to become an underlying technology for disparate products, including: Map-building software for robotic manipulation, especially in factory and logistics applications. Software that aligns LIDAR scans to produce as-built models. Evidence Meshes could improve the quality of alignment even with uncertainties in LIDAR pose. Perception and navigation software for autonomous unmanned vehicles. Infrastructure-free localization technologies such as SLAM.
		<P>
		
		<TABLE  role="presentation" cellSpacing="1" cellPadding="2" width="100%" border="0">
		  <TBODY>
		  <TR>
		      <TD><DIV align="left"><B>TECHNOLOGY TAXONOMY MAPPING</B> (NASA's technology taxonomy has been developed by the SBIR-STTR program to disseminate awareness of proposed and awarded R/R&D in the agency. It is a listing of over 100 technologies, sorted into broad categories, of interest to NASA.)</DIV>
		      
				
		</TD>
	      </TR>
		  <TR>
		    <TD>
		      <DIV align="left">
			      Perception/Vision<BR>
			      Robotics (see also Control & Monitoring; Sensors)<BR>
		      </DIV>
		    </TD>
		  </TR>
		 </TBODY>
		</TABLE>
		<HR noShade SIZE="3">
		<FONT size=-1>Form Generated on 04-19-17 12:45</FONT>

</BODY>
</HTML>
